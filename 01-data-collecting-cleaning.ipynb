{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./CSVs')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get 10000 posts and put it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_posts(subreddit):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    to_be_df = []\n",
    "    counter = 0\n",
    "    if counter == 0:\n",
    "        created_utc = ''\n",
    "    else:\n",
    "        created_utc = created_utc\n",
    "        \n",
    "    while counter < 105:\n",
    "        params = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 100,\n",
    "        'before': created_utc}\n",
    "    \n",
    "        res = requests.get(url, params)\n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        created_utc = posts[99]['created_utc']\n",
    "        \n",
    "        tempdf = pd.DataFrame(posts)\n",
    "        tempdf = tempdf[['subreddit', 'selftext', 'title']]\n",
    "        \n",
    "        to_be_df.append(tempdf)\n",
    "        counter += 1\n",
    "        print(f'scraped {counter} times')\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.concat(to_be_df, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped 1 times\n",
      "scraped 2 times\n",
      "scraped 3 times\n",
      "scraped 4 times\n",
      "scraped 5 times\n",
      "scraped 6 times\n",
      "scraped 7 times\n",
      "scraped 8 times\n",
      "scraped 9 times\n",
      "scraped 10 times\n",
      "scraped 11 times\n",
      "scraped 12 times\n",
      "scraped 13 times\n",
      "scraped 14 times\n",
      "scraped 15 times\n",
      "scraped 16 times\n",
      "scraped 17 times\n",
      "scraped 18 times\n",
      "scraped 19 times\n",
      "scraped 20 times\n",
      "scraped 21 times\n",
      "scraped 22 times\n",
      "scraped 23 times\n",
      "scraped 24 times\n",
      "scraped 25 times\n",
      "scraped 26 times\n",
      "scraped 27 times\n",
      "scraped 28 times\n",
      "scraped 29 times\n",
      "scraped 30 times\n",
      "scraped 31 times\n",
      "scraped 32 times\n",
      "scraped 33 times\n",
      "scraped 34 times\n",
      "scraped 35 times\n",
      "scraped 36 times\n",
      "scraped 37 times\n",
      "scraped 38 times\n",
      "scraped 39 times\n",
      "scraped 40 times\n",
      "scraped 41 times\n",
      "scraped 42 times\n",
      "scraped 43 times\n",
      "scraped 44 times\n",
      "scraped 45 times\n",
      "scraped 46 times\n",
      "scraped 47 times\n",
      "scraped 48 times\n",
      "scraped 49 times\n",
      "scraped 50 times\n",
      "scraped 51 times\n",
      "scraped 52 times\n",
      "scraped 53 times\n",
      "scraped 54 times\n",
      "scraped 55 times\n",
      "scraped 56 times\n",
      "scraped 57 times\n",
      "scraped 58 times\n",
      "scraped 59 times\n",
      "scraped 60 times\n",
      "scraped 61 times\n",
      "scraped 62 times\n",
      "scraped 63 times\n",
      "scraped 64 times\n",
      "scraped 65 times\n",
      "scraped 66 times\n",
      "scraped 67 times\n",
      "scraped 68 times\n",
      "scraped 69 times\n",
      "scraped 70 times\n",
      "scraped 71 times\n",
      "scraped 72 times\n",
      "scraped 73 times\n",
      "scraped 74 times\n",
      "scraped 75 times\n",
      "scraped 76 times\n",
      "scraped 77 times\n",
      "scraped 78 times\n",
      "scraped 79 times\n",
      "scraped 80 times\n",
      "scraped 81 times\n",
      "scraped 82 times\n",
      "scraped 83 times\n",
      "scraped 84 times\n",
      "scraped 85 times\n",
      "scraped 86 times\n",
      "scraped 87 times\n",
      "scraped 88 times\n",
      "scraped 89 times\n",
      "scraped 90 times\n",
      "scraped 91 times\n",
      "scraped 92 times\n",
      "scraped 93 times\n",
      "scraped 94 times\n",
      "scraped 95 times\n",
      "scraped 96 times\n",
      "scraped 97 times\n",
      "scraped 98 times\n",
      "scraped 99 times\n",
      "scraped 100 times\n",
      "scraped 101 times\n",
      "scraped 102 times\n",
      "scraped 103 times\n",
      "scraped 104 times\n",
      "scraped 105 times\n"
     ]
    }
   ],
   "source": [
    "world_news = scrape_posts('worldnews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>Staggering Photos Capture a Frozen Apartment C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>Dow Jones closes down 3,000 points, or almost ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>Stocks making the biggest moves in the premark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>مستشار أردوغان: تركيا أول دولة اعترفت بحقوق ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>Sotheby’s auction house is getting into the NF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit selftext                                              title\n",
       "0  worldnews           Staggering Photos Capture a Frozen Apartment C...\n",
       "1  worldnews           Dow Jones closes down 3,000 points, or almost ...\n",
       "2  worldnews           Stocks making the biggest moves in the premark...\n",
       "3  worldnews           مستشار أردوغان: تركيا أول دولة اعترفت بحقوق ال...\n",
       "4  worldnews           Sotheby’s auction house is getting into the NF..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped 1 times\n",
      "scraped 2 times\n",
      "scraped 3 times\n",
      "scraped 4 times\n",
      "scraped 5 times\n",
      "scraped 6 times\n",
      "scraped 7 times\n",
      "scraped 8 times\n",
      "scraped 9 times\n",
      "scraped 10 times\n",
      "scraped 11 times\n",
      "scraped 12 times\n",
      "scraped 13 times\n",
      "scraped 14 times\n",
      "scraped 15 times\n",
      "scraped 16 times\n",
      "scraped 17 times\n",
      "scraped 18 times\n",
      "scraped 19 times\n",
      "scraped 20 times\n",
      "scraped 21 times\n",
      "scraped 22 times\n",
      "scraped 23 times\n",
      "scraped 24 times\n",
      "scraped 25 times\n",
      "scraped 26 times\n",
      "scraped 27 times\n",
      "scraped 28 times\n",
      "scraped 29 times\n",
      "scraped 30 times\n",
      "scraped 31 times\n",
      "scraped 32 times\n",
      "scraped 33 times\n",
      "scraped 34 times\n",
      "scraped 35 times\n",
      "scraped 36 times\n",
      "scraped 37 times\n",
      "scraped 38 times\n",
      "scraped 39 times\n",
      "scraped 40 times\n",
      "scraped 41 times\n",
      "scraped 42 times\n",
      "scraped 43 times\n",
      "scraped 44 times\n",
      "scraped 45 times\n",
      "scraped 46 times\n",
      "scraped 47 times\n",
      "scraped 48 times\n",
      "scraped 49 times\n",
      "scraped 50 times\n",
      "scraped 51 times\n",
      "scraped 52 times\n",
      "scraped 53 times\n",
      "scraped 54 times\n",
      "scraped 55 times\n",
      "scraped 56 times\n",
      "scraped 57 times\n",
      "scraped 58 times\n",
      "scraped 59 times\n",
      "scraped 60 times\n",
      "scraped 61 times\n",
      "scraped 62 times\n",
      "scraped 63 times\n",
      "scraped 64 times\n",
      "scraped 65 times\n",
      "scraped 66 times\n",
      "scraped 67 times\n",
      "scraped 68 times\n",
      "scraped 69 times\n",
      "scraped 70 times\n",
      "scraped 71 times\n",
      "scraped 72 times\n",
      "scraped 73 times\n",
      "scraped 74 times\n",
      "scraped 75 times\n",
      "scraped 76 times\n",
      "scraped 77 times\n",
      "scraped 78 times\n",
      "scraped 79 times\n",
      "scraped 80 times\n",
      "scraped 81 times\n",
      "scraped 82 times\n",
      "scraped 83 times\n",
      "scraped 84 times\n",
      "scraped 85 times\n",
      "scraped 86 times\n",
      "scraped 87 times\n",
      "scraped 88 times\n",
      "scraped 89 times\n",
      "scraped 90 times\n",
      "scraped 91 times\n",
      "scraped 92 times\n",
      "scraped 93 times\n",
      "scraped 94 times\n",
      "scraped 95 times\n",
      "scraped 96 times\n",
      "scraped 97 times\n",
      "scraped 98 times\n",
      "scraped 99 times\n",
      "scraped 100 times\n",
      "scraped 101 times\n",
      "scraped 102 times\n",
      "scraped 103 times\n",
      "scraped 104 times\n",
      "scraped 105 times\n"
     ]
    }
   ],
   "source": [
    "history = scrape_posts('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>history</td>\n",
       "      <td></td>\n",
       "      <td>Buy Facebook Reviews - USA Facebook Page Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>history</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Why is it that in the religious texts of the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>history</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>What happened to all the corpses of the tens o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>history</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Why are there so few Lipka Tatars in today's P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>history</td>\n",
       "      <td></td>\n",
       "      <td>Buy Facebook Reviews - USA Facebook Page Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>history</td>\n",
       "      <td></td>\n",
       "      <td>Just found my new favorite model. Check out li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>history</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>I am interested in learning world history. Cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>history</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Are East Asian people descendants of Ancient E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>history</td>\n",
       "      <td></td>\n",
       "      <td>40,000-year-old bone reveals East Asia's ancie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>history</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>What would the Soviet Union’s push of the Germ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit   selftext                                              title\n",
       "0       history             Buy Facebook Reviews - USA Facebook Page Posit...\n",
       "1       history  [removed]  Why is it that in the religious texts of the A...\n",
       "2       history  [removed]  What happened to all the corpses of the tens o...\n",
       "3       history  [removed]  Why are there so few Lipka Tatars in today's P...\n",
       "4       history             Buy Facebook Reviews - USA Facebook Page Posit...\n",
       "...         ...        ...                                                ...\n",
       "10495   history             Just found my new favorite model. Check out li...\n",
       "10496   history  [removed]  I am interested in learning world history. Cou...\n",
       "10497   history  [removed]  Are East Asian people descendants of Ancient E...\n",
       "10498   history             40,000-year-old bone reveals East Asia's ancie...\n",
       "10499   history  [removed]  What would the Soviet Union’s push of the Germ...\n",
       "\n",
       "[10500 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make everything lowercase and remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_news['title'] = world_news['title'].map(lambda x: x.lower())\n",
    "world_news['title'] = world_news['title'].map(lambda x: ''.join([y for y in list(x.lower()) if y in string.ascii_lowercase + ' -' + string.digits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['title'] = history['title'].map(lambda x: x.lower())\n",
    "history['title'] = history['title'].map(lambda x: ''.join([y for y in list(x.lower()) if y in string.ascii_lowercase + ' -' +string.digits]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of titles that have websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history[history['title'].str.contains('http') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_news = world_news[world_news['title'].str.contains('http') == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values, and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_news['title'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_news = world_news[world_news['title'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_news = world_news[world_news['title'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['title'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history[history['title'].notnull()]\n",
    "history = history[history['title'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv('./CSVs/history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_news.to_csv('./CSVs/world_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
